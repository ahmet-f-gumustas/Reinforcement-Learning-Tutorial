"""
Lunar Lander - GerÃ§ek ZamanlÄ± Oyun SimÃ¼lasyonu
===============================================
Bu Ã¶rnek, LunarLander-v3 ortamÄ±nÄ± kullanarak interaktif bir oyun sunar.

Modlar:
1. Ä°nsan Modu: Klavye ile kontrol et
2. AI Modu: EÄŸitilmiÅŸ DQN ajanÄ±nÄ± izle
3. EÄŸitim Modu: DQN ajanÄ±nÄ± eÄŸit

Kontroller (Ä°nsan Modu):
- Sol Ok / A: Sol motor
- SaÄŸ Ok / D: SaÄŸ motor
- YukarÄ± Ok / W / Space: Ana motor
- R: Yeniden baÅŸlat
- Q / ESC: Ã‡Ä±kÄ±ÅŸ
"""

import gymnasium as gym
import numpy as np
import pygame
import torch
import torch.nn as nn
import torch.optim as optim
from collections import deque
import random
import os
from pathlib import Path

# Output klasÃ¶rÃ¼
SCRIPT_NAME = Path(__file__).stem
OUTPUT_DIR = Path(__file__).parent / "output" / SCRIPT_NAME
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Cihaz seÃ§imi
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class DQN(nn.Module):
    """Deep Q-Network modeli."""

    def __init__(self, state_size, action_size, hidden_size=128):
        super(DQN, self).__init__()
        self.fc1 = nn.Linear(state_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, action_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return self.fc3(x)


class ReplayBuffer:
    """Deneyim tekrar tamponu."""

    def __init__(self, capacity=100000):
        self.buffer = deque(maxlen=capacity)

    def push(self, state, action, reward, next_state, done):
        self.buffer.append((state, action, reward, next_state, done))

    def sample(self, batch_size):
        batch = random.sample(self.buffer, batch_size)
        states, actions, rewards, next_states, dones = zip(*batch)
        return (np.array(states), np.array(actions), np.array(rewards),
                np.array(next_states), np.array(dones))

    def __len__(self):
        return len(self.buffer)


class DQNAgent:
    """DQN tabanlÄ± ajan."""

    def __init__(self, state_size, action_size, lr=0.001, gamma=0.99,
                 epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):
        self.state_size = state_size
        self.action_size = action_size
        self.gamma = gamma
        self.epsilon = epsilon
        self.epsilon_decay = epsilon_decay
        self.epsilon_min = epsilon_min

        # Ana ve hedef aÄŸlar
        self.policy_net = DQN(state_size, action_size).to(device)
        self.target_net = DQN(state_size, action_size).to(device)
        self.target_net.load_state_dict(self.policy_net.state_dict())

        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)
        self.memory = ReplayBuffer()
        self.batch_size = 64
        self.update_target_every = 10
        self.steps = 0

    def choose_action(self, state, training=True):
        if training and random.random() < self.epsilon:
            return random.randrange(self.action_size)

        with torch.no_grad():
            state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)
            q_values = self.policy_net(state_tensor)
            return q_values.argmax().item()

    def remember(self, state, action, reward, next_state, done):
        self.memory.push(state, action, reward, next_state, done)

    def train_step(self):
        if len(self.memory) < self.batch_size:
            return 0

        states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)

        states = torch.FloatTensor(states).to(device)
        actions = torch.LongTensor(actions).to(device)
        rewards = torch.FloatTensor(rewards).to(device)
        next_states = torch.FloatTensor(next_states).to(device)
        dones = torch.FloatTensor(dones).to(device)

        # Mevcut Q deÄŸerleri
        current_q = self.policy_net(states).gather(1, actions.unsqueeze(1))

        # Hedef Q deÄŸerleri
        with torch.no_grad():
            next_q = self.target_net(next_states).max(1)[0]
            target_q = rewards + (1 - dones) * self.gamma * next_q

        # KayÄ±p ve gÃ¼ncelleme
        loss = nn.MSELoss()(current_q.squeeze(), target_q)
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        # Epsilon azalt
        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)

        # Hedef aÄŸÄ± gÃ¼ncelle
        self.steps += 1
        if self.steps % self.update_target_every == 0:
            self.target_net.load_state_dict(self.policy_net.state_dict())

        return loss.item()

    def save(self, path):
        torch.save({
            'policy_net': self.policy_net.state_dict(),
            'target_net': self.target_net.state_dict(),
            'epsilon': self.epsilon
        }, path)
        print(f"Model kaydedildi: {path}")

    def load(self, path):
        if os.path.exists(path):
            checkpoint = torch.load(path, map_location=device)
            self.policy_net.load_state_dict(checkpoint['policy_net'])
            self.target_net.load_state_dict(checkpoint['target_net'])
            self.epsilon = checkpoint.get('epsilon', 0.01)
            print(f"Model yÃ¼klendi: {path}")
            return True
        return False


class LunarLanderGame:
    """GerÃ§ek zamanlÄ± Lunar Lander oyunu."""

    ACTION_NAMES = ["HiÃ§bir ÅŸey", "Sol motor", "Ana motor", "SaÄŸ motor"]

    def __init__(self):
        self.env = gym.make("LunarLander-v3", render_mode="human")
        self.state_size = self.env.observation_space.shape[0]
        self.action_size = self.env.action_space.n

        # DQN ajanÄ±
        self.agent = DQNAgent(self.state_size, self.action_size)
        self.model_path = OUTPUT_DIR / "dqn_model.pt"

        # Oyun durumu
        self.state = None
        self.total_reward = 0
        self.episode = 0
        self.step_count = 0
        self.done = True
        self.mode = "human"  # "human", "ai", "train"

        # Ä°statistikler
        self.rewards_history = []
        self.best_reward = float('-inf')

    def reset(self):
        """OrtamÄ± sÄ±fÄ±rla."""
        self.state, _ = self.env.reset()
        self.total_reward = 0
        self.step_count = 0
        self.done = False
        self.episode += 1
        return self.state

    def get_human_action(self, keys):
        """Klavye giriÅŸinden aksiyon al."""
        # 0: HiÃ§bir ÅŸey, 1: Sol, 2: Ana motor, 3: SaÄŸ
        if keys[pygame.K_UP] or keys[pygame.K_w] or keys[pygame.K_SPACE]:
            return 2  # Ana motor
        elif keys[pygame.K_LEFT] or keys[pygame.K_a]:
            return 1  # Sol motor
        elif keys[pygame.K_RIGHT] or keys[pygame.K_d]:
            return 3  # SaÄŸ motor
        return 0  # HiÃ§bir ÅŸey

    def step(self, action):
        """Bir adÄ±m at."""
        next_state, reward, terminated, truncated, info = self.env.step(action)
        done = terminated or truncated

        self.total_reward += reward
        self.step_count += 1

        if self.mode == "train":
            self.agent.remember(self.state, action, reward, next_state, done)
            self.agent.train_step()

        self.state = next_state
        self.done = done

        if done:
            self.rewards_history.append(self.total_reward)
            if self.total_reward > self.best_reward:
                self.best_reward = self.total_reward

        return next_state, reward, done, info

    def run_human_mode(self):
        """Ä°nsan kontrolÃ¼ ile oyna."""
        print("\n" + "=" * 60)
        print("ğŸš€ LUNAR LANDER - Ä°NSAN MODU")
        print("=" * 60)
        print("Kontroller:")
        print("  - Sol Ok / A: Sol motor")
        print("  - SaÄŸ Ok / D: SaÄŸ motor")
        print("  - YukarÄ± Ok / W / Space: Ana motor")
        print("  - R: Yeniden baÅŸlat")
        print("  - Q / ESC: Ã‡Ä±kÄ±ÅŸ")
        print("=" * 60)

        self.mode = "human"
        pygame.init()

        running = True
        clock = pygame.time.Clock()
        self.reset()

        while running:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    running = False
                elif event.type == pygame.KEYDOWN:
                    if event.key in (pygame.K_q, pygame.K_ESCAPE):
                        running = False
                    elif event.key == pygame.K_r:
                        self.reset()
                        print(f"\n[Yeniden baÅŸlatÄ±ldÄ±] Episode {self.episode}")

            if not self.done:
                keys = pygame.key.get_pressed()
                action = self.get_human_action(keys)
                _, reward, done, _ = self.step(action)

                if done:
                    result = "âœ… BAÅARILI!" if self.total_reward > 200 else "âŒ DÃœÅTÃœ!"
                    print(f"Episode {self.episode}: {result} Skor: {self.total_reward:.1f}")
            else:
                # Otomatik yeniden baÅŸlat
                pygame.time.wait(1000)
                self.reset()

            clock.tick(30)

        self.env.close()
        pygame.quit()

    def run_ai_mode(self, episodes=5):
        """EÄŸitilmiÅŸ AI ile oyna."""
        print("\n" + "=" * 60)
        print("ğŸ¤– LUNAR LANDER - AI MODU")
        print("=" * 60)

        self.mode = "ai"

        # Modeli yÃ¼kle
        if not self.agent.load(self.model_path):
            print("âš ï¸  EÄŸitilmiÅŸ model bulunamadÄ±!")
            print("Ã–nce eÄŸitim modunu Ã§alÄ±ÅŸtÄ±rÄ±n: run_training_mode()")
            return

        self.agent.epsilon = 0  # KeÅŸif yok, sadece sÃ¶mÃ¼rÃ¼

        for ep in range(episodes):
            self.reset()
            print(f"\n[AI Oynuyor] Episode {ep + 1}/{episodes}")

            while not self.done:
                action = self.agent.choose_action(self.state, training=False)
                self.step(action)
                pygame.time.wait(20)

            result = "âœ… BAÅARILI!" if self.total_reward > 200 else "âŒ DÃœÅTÃœ!"
            print(f"SonuÃ§: {result} Skor: {self.total_reward:.1f}")

        avg_reward = np.mean(self.rewards_history[-episodes:])
        print(f"\nğŸ“Š Ortalama Skor: {avg_reward:.1f}")

        self.env.close()

    def run_training_mode(self, episodes=500, save_every=50):
        """AI ajanÄ±nÄ± eÄŸit."""
        print("\n" + "=" * 60)
        print("ğŸ“ LUNAR LANDER - EÄÄ°TÄ°M MODU")
        print("=" * 60)
        print(f"EÄŸitim: {episodes} episode")
        print(f"KayÄ±t: Her {save_every} episode")
        print(f"Cihaz: {device}")
        print("=" * 60)

        self.mode = "train"

        # Render olmadan eÄŸit (hÄ±zlÄ±)
        self.env.close()
        self.env = gym.make("LunarLander-v3")

        best_avg = float('-inf')

        for ep in range(episodes):
            self.reset()

            while not self.done:
                action = self.agent.choose_action(self.state, training=True)
                self.step(action)

            # Ä°statistikler
            avg_reward = np.mean(self.rewards_history[-100:]) if self.rewards_history else 0

            if (ep + 1) % 10 == 0:
                print(f"Episode {ep + 1}/{episodes} | "
                      f"Skor: {self.total_reward:.1f} | "
                      f"Ort(100): {avg_reward:.1f} | "
                      f"Îµ: {self.agent.epsilon:.3f}")

            # En iyi modeli kaydet
            if avg_reward > best_avg and ep > 100:
                best_avg = avg_reward
                self.agent.save(self.model_path)

            # Periyodik kayÄ±t
            if (ep + 1) % save_every == 0:
                self.agent.save(self.model_path)

        # Son kayÄ±t
        self.agent.save(self.model_path)

        print("\n" + "=" * 60)
        print("âœ… EÄÄ°TÄ°M TAMAMLANDI!")
        print(f"En iyi ortalama: {best_avg:.1f}")
        print(f"Model: {self.model_path}")
        print("=" * 60)

        self.env.close()
        return self.rewards_history

    def demo_mode(self):
        """HÄ±zlÄ± demo - eÄŸitim + AI gÃ¶sterimi."""
        print("\n" + "=" * 60)
        print("ğŸ® LUNAR LANDER - DEMO MODU")
        print("=" * 60)

        # KÄ±sa eÄŸitim
        print("\nğŸ“š HÄ±zlÄ± eÄŸitim baÅŸlÄ±yor (200 episode)...")
        self.run_training_mode(episodes=200, save_every=50)

        # AI gÃ¶sterimi
        print("\nğŸ¤– EÄŸitilmiÅŸ AI gÃ¶sterimi...")
        self.env = gym.make("LunarLander-v3", render_mode="human")
        self.run_ai_mode(episodes=3)


def print_menu():
    """Ana menÃ¼yÃ¼ gÃ¶ster."""
    print("\n" + "=" * 60)
    print("ğŸš€ LUNAR LANDER - ANA MENÃœ")
    print("=" * 60)
    print("1. ğŸ‘¤ Ä°nsan Modu (Klavye ile oyna)")
    print("2. ğŸ¤– AI Modu (EÄŸitilmiÅŸ ajanÄ± izle)")
    print("3. ğŸ“ EÄŸitim Modu (AI ajanÄ±nÄ± eÄŸit)")
    print("4. ğŸ® Demo Modu (EÄŸitim + GÃ¶sterim)")
    print("5. âŒ Ã‡Ä±kÄ±ÅŸ")
    print("=" * 60)


def main():
    print("\n" + "=" * 60)
    print("ğŸŒ™ LUNAR LANDER - GerÃ§ek ZamanlÄ± Oyun SimÃ¼lasyonu")
    print("=" * 60)
    print(f"Output klasÃ¶rÃ¼: {OUTPUT_DIR}")
    print(f"Cihaz: {device}")

    game = LunarLanderGame()

    while True:
        print_menu()
        try:
            choice = input("SeÃ§iminiz (1-5): ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nÃ‡Ä±kÄ±lÄ±yor...")
            break

        if choice == "1":
            game.run_human_mode()
        elif choice == "2":
            game.run_ai_mode(episodes=5)
        elif choice == "3":
            try:
                episodes = int(input("Episode sayÄ±sÄ± (varsayÄ±lan 500): ").strip() or "500")
            except ValueError:
                episodes = 500
            game.run_training_mode(episodes=episodes)
        elif choice == "4":
            game.demo_mode()
        elif choice == "5":
            print("GÃ¼le gÃ¼le! ğŸ‘‹")
            break
        else:
            print("GeÃ§ersiz seÃ§im!")

    game.env.close()


if __name__ == "__main__":
    main()
